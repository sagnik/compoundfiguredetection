{"Caption":"Figure 8. General software-pipelined prefetching","ImageText":[{"Text":"prologue;","TextBB":[483.167,377.856,543.142,389.457],"Rotation":0},{"Text":"for","TextBB":[483.167,390.189,503.158,401.79],"Rotation":0},{"Text":"j=0","TextBB":[509.825,390.189,529.817,401.79],"Rotation":0},{"Text":"to","TextBB":[536.317,390.189,549.644,401.79],"Rotation":0},{"Text":"N-kD-1","TextBB":[556.311,390.189,596.294,401.79],"Rotation":0},{"Text":"do","TextBB":[602.794,390.189,616.122,401.79],"Rotation":0},{"Text":"☞","TextBB":[483.889,380.833,483.889,413.333],"Rotation":0},{"Text":"✍✏","TextBB":[550.694,457.083,561.806,489.583],"Rotation":0},{"Text":"✑","TextBB":[561.25,455.278,561.25,487.778],"Rotation":0},{"Text":"✎","TextBB":[561.806,457.083,561.806,489.583],"Rotation":0},{"Text":"✑","TextBB":[581.25,468.194,581.25,500.694],"Rotation":0},{"Text":"✍","TextBB":[570.694,470.139,570.694,502.639],"Rotation":0},{"Text":"✒","TextBB":[581.389,470.278,581.389,502.778],"Rotation":0},{"Text":"i=j+(k-2)D;","TextBB":[504,505.356,577.303,516.957],"Rotation":0},{"Text":"visit","TextBB":[504,518.356,537.319,529.957],"Rotation":0},{"Text":"(","TextBB":[543.819,518.356,550.483,529.957],"Rotation":0},{"Text":"✍✓","TextBB":[550.694,503.611,561.389,536.111],"Rotation":0},{"Text":"✑","TextBB":[561.25,501.528,561.25,534.028],"Rotation":0},{"Text":"✒","TextBB":[561.389,503.611,561.389,536.111],"Rotation":0},{"Text":");","TextBB":[566.667,518.356,579.994,529.957],"Rotation":0},{"Text":"code","TextBB":[586.661,518.356,613.317,529.957],"Rotation":0},{"Text":"2","TextBB":[619.817,518.356,626.481,529.957],"Rotation":0},{"Text":"for","TextBB":[632.98,518.356,652.972,529.957],"Rotation":0},{"Text":"element","TextBB":[659.639,518.356,706.286,529.957],"Rotation":0},{"Text":"i;","TextBB":[712.786,518.356,726.114,529.957],"Rotation":0},{"Text":"prefetch","TextBB":[504,531.356,557.311,542.957],"Rotation":0},{"Text":"(","TextBB":[563.811,531.356,570.475,542.957],"Rotation":0},{"Text":"✍✙","TextBB":[570.694,516.528,581.25,549.028],"Rotation":0},{"Text":"✑","TextBB":[581.25,514.722,581.25,547.222],"Rotation":0},{"Text":"✚","TextBB":[581.25,516.528,581.25,549.028],"Rotation":0},{"Text":");","TextBB":[586.667,531.356,599.994,542.957],"Rotation":0},{"Text":"✔✕✔☛✔✖✔◗✔✕✔","TextBB":[505,533.472,535.833,565.972],"Rotation":0},{"Text":"i=j;","TextBB":[504,572.023,530.656,583.623],"Rotation":0},{"Text":"✌","TextBB":[483.889,572.917,483.889,605.417],"Rotation":0},{"Text":"visit","TextBB":[504,585.356,537.319,596.957],"Rotation":0},{"Text":"(","TextBB":[543.819,585.356,550.483,596.957],"Rotation":0},{"Text":"✍","TextBB":[550.694,570.556,550.694,603.056],"Rotation":0},{"Text":"✑","TextBB":[561.25,568.75,561.25,601.25],"Rotation":0},{"Text":"✗","TextBB":[561.389,570.694,561.389,603.194],"Rotation":0},{"Text":");","TextBB":[567.167,585.356,580.494,596.957],"Rotation":0},{"Text":"code","TextBB":[587.161,585.356,613.817,596.957],"Rotation":0},{"Text":"k","TextBB":[620.317,585.356,626.981,596.957],"Rotation":0},{"Text":"for","TextBB":[633.647,585.356,653.639,596.957],"Rotation":0},{"Text":"element","TextBB":[660.139,585.356,706.786,596.957],"Rotation":0},{"Text":"i;","TextBB":[713.286,585.356,726.614,596.957],"Rotation":0},{"Text":"i=j+(k-1)D;","TextBB":[504,458.856,577.303,470.457],"Rotation":0},{"Text":"visit","TextBB":[504,471.856,537.319,483.457],"Rotation":0},{"Text":"(","TextBB":[543.819,471.856,550.483,483.457],"Rotation":0},{"Text":");","TextBB":[566.667,471.856,579.994,483.457],"Rotation":0},{"Text":"code","TextBB":[586.661,471.856,613.317,483.457],"Rotation":0},{"Text":"1","TextBB":[619.817,471.856,626.481,483.457],"Rotation":0},{"Text":"for","TextBB":[632.98,471.856,652.972,483.457],"Rotation":0},{"Text":"element","TextBB":[659.639,471.856,706.286,483.457],"Rotation":0},{"Text":"i;","TextBB":[712.786,471.856,726.114,483.457],"Rotation":0},{"Text":"prefetch","TextBB":[504,484.856,557.311,496.457],"Rotation":0},{"Text":"(","TextBB":[563.811,484.856,570.475,496.457],"Rotation":0},{"Text":");","TextBB":[586.667,484.856,599.994,496.457],"Rotation":0},{"Text":"epilogue;","TextBB":[483.167,605.356,543.142,616.957],"Rotation":0},{"Text":"✍","TextBB":[570.694,423.75,570.694,456.25],"Rotation":0},{"Text":"✑","TextBB":[581.25,421.944,581.25,454.444],"Rotation":0},{"Text":"✎","TextBB":[581.806,423.611,581.806,456.111],"Rotation":0},{"Text":"i=j+kD;","TextBB":[504,413.023,550.647,424.623],"Rotation":0},{"Text":"code","TextBB":[504,425.523,530.656,437.123],"Rotation":0},{"Text":"0","TextBB":[537.156,425.523,543.819,437.123],"Rotation":0},{"Text":"for","TextBB":[550.486,425.523,570.478,437.123],"Rotation":0},{"Text":"element","TextBB":[576.978,425.523,623.625,437.123],"Rotation":0},{"Text":"i;","TextBB":[630.125,425.523,643.453,437.123],"Rotation":0},{"Text":"prefetch","TextBB":[504,438.523,557.311,450.124],"Rotation":0},{"Text":"(","TextBB":[563.811,438.523,570.475,450.124],"Rotation":0},{"Text":");","TextBB":[586.667,438.523,599.994,450.123],"Rotation":0}],"Mention":["We have implemented software-pipelined prefetching by\nmodifying our group prefetching algorithm. The code stages\nare kept almost unchanged. To apply the general model in\nFigure 8, we use a circular array for state information. Since\ncode 0 and code k of the same element is processed \u001F9v it-\nerations away, we ensure the array size \u0082 is at least \u001Fhv\u0083,\u0084- .\n","generated. The second partition step in \u0093two-step cache\u0094 is\nshown as part of the join phase performance. Moreover, we\nemploy prefetching in the join phase to enhance the cache\npartitioning schemes wherever possible.\nFigure 18(a)-(c) show experiments joining a 200MB build\nrelation with a 400MB probe relation. Every build tu-\nple matches two probe tuples. We increase the tuple size,\nwhich results in decreasing numbers of tuples in the rela-\ntions and the downward trends of the curves. \u0093Direct cache\u0094\nachieves the best performance in the join phase by avoiding\nmost cache misses. However, it suffers from larger over-\nheads in the partition phase because it generates many more\npartitions. \u0093Two-step cache\u0094 suffers from the overhead of\nthe additional partition step and is 50-150% worse than the\nprefetching schemes. Overall, our prefetching schemes are\nthe best (slightly better than \u0093direct cache\u0094 even under ex-\nclusive use of the cache). In Figure 18(d), we keep the tuple\nsize to be 100B and vary the percentage of tuples that have\nmatches. Again, we see similar trends as in Figure 18(c).\nIn Figure 18, our prefetching techniques achieve 1.4-2.5X\nspeedups for the partition phase, 2.1-2.9X speedups for the\njoin phase, and 1.9-2.7X speedups overall compared to the\nbaseline algorithm.9\n"],"Page":6,"Number":8,"Type":"Figure","CaptionBB":[479,626,736,642],"Height":1100,"Width":850,"DPI":100,"ImageBB":[439,371,777,619]}