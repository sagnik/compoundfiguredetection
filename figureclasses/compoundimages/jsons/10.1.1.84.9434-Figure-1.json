{"Caption":"Figure 1: Illustrative example of the process of learning semantic class densities. Graphs (a)-(c) show three examples of the feature distributions of individual images. Graph (d) presents the feature distribution over 1,000 images. Although not necessarily dominant in any image, the concept density (shown in red) dominates over the entire training set. ","ImageText":[{"Text":"4","TextBB":[598.413,76.5369,600.725,80.383],"Rotation":0},{"Text":"400","TextBB":[82.3719,84.0881,92.6471,89.7863],"Rotation":0},{"Text":"400","TextBB":[247.372,84.0881,257.647,89.7863],"Rotation":0},{"Text":"Distr.","TextBB":[183.09,89.6326,197.462,95.3307],"Rotation":0},{"Text":"1","TextBB":[199.174,89.6326,202.6,95.3307],"Rotation":0},{"Text":"Distr.","TextBB":[183.09,96.7424,197.462,102.441],"Rotation":0},{"Text":"2","TextBB":[199.174,96.7424,202.6,102.441],"Rotation":0},{"Text":"Distr.","TextBB":[183.09,103.852,197.462,109.55],"Rotation":0},{"Text":"3","TextBB":[199.174,103.852,202.6,109.55],"Rotation":0},{"Text":"Mixture","TextBB":[183.09,110.962,203.283,116.66],"Rotation":0},{"Text":"of","TextBB":[204.996,110.962,210.133,116.66],"Rotation":0},{"Text":"Distr.","TextBB":[211.846,110.962,226.218,116.66],"Rotation":0},{"Text":"350","TextBB":[82.3719,97.6409,92.6471,103.339],"Rotation":0},{"Text":"300","TextBB":[82.3719,111.192,92.6471,116.89],"Rotation":0},{"Text":"Distr.","TextBB":[348.09,89.6326,362.462,95.3307],"Rotation":0},{"Text":"1","TextBB":[364.174,89.6326,367.6,95.3307],"Rotation":0},{"Text":"Distr.","TextBB":[348.09,96.7424,362.462,102.441],"Rotation":0},{"Text":"2","TextBB":[364.174,96.7424,367.6,102.441],"Rotation":0},{"Text":"Distr.","TextBB":[348.09,103.852,362.462,109.55],"Rotation":0},{"Text":"3","TextBB":[364.174,103.852,367.6,109.55],"Rotation":0},{"Text":"Mixture","TextBB":[348.09,110.962,368.283,116.66],"Rotation":0},{"Text":"of","TextBB":[369.996,110.962,375.133,116.66],"Rotation":0},{"Text":"Distr.","TextBB":[376.846,110.962,391.218,116.66],"Rotation":0},{"Text":"350","TextBB":[247.372,97.6409,257.647,103.339],"Rotation":0},{"Text":"300","TextBB":[247.372,111.192,257.647,116.89],"Rotation":0},{"Text":"300","TextBB":[412.206,111.192,422.481,116.89],"Rotation":0},{"Text":"250","TextBB":[247.372,124.745,257.647,130.443],"Rotation":0},{"Text":"250","TextBB":[412.206,124.745,422.481,130.443],"Rotation":0},{"Text":"200","TextBB":[82.3719,138.323,92.6471,144.021],"Rotation":0},{"Text":"200","TextBB":[247.372,138.323,257.647,144.021],"Rotation":0},{"Text":"200","TextBB":[412.206,138.323,422.481,144.021],"Rotation":0},{"Text":"150","TextBB":[82.3719,151.876,92.6471,157.574],"Rotation":0},{"Text":"150","TextBB":[247.372,151.876,257.647,157.574],"Rotation":0},{"Text":"150","TextBB":[412.206,151.876,422.481,157.574],"Rotation":0},{"Text":"100","TextBB":[82.3719,165.428,92.6471,171.127],"Rotation":0},{"Text":"100","TextBB":[247.372,165.428,257.647,171.127],"Rotation":0},{"Text":"100","TextBB":[412.206,165.428,422.481,171.127],"Rotation":0},{"Text":"50","TextBB":[85.8114,178.98,92.6615,184.678],"Rotation":0},{"Text":"50","TextBB":[250.811,178.98,257.661,184.678],"Rotation":0},{"Text":"50","TextBB":[415.644,178.98,422.495,184.678],"Rotation":0},{"Text":"−50","TextBB":[112.3,196.87,122.748,202.568],"Rotation":0},{"Text":"0","TextBB":[160.581,196.87,164.006,202.568],"Rotation":0},{"Text":"0","TextBB":[254.225,192.558,257.65,198.256],"Rotation":0},{"Text":"50","TextBB":[201.803,196.87,208.653,202.568],"Rotation":0},{"Text":"−50","TextBB":[277.3,196.87,287.748,202.568],"Rotation":0},{"Text":"0","TextBB":[325.581,196.87,329.006,202.568],"Rotation":0},{"Text":"(a)","TextBB":[150.333,208.328,164.144,219.536],"Rotation":0},{"Text":"Distr.","TextBB":[512.924,89.6326,527.295,95.3307],"Rotation":0},{"Text":"1","TextBB":[529.008,89.6326,532.433,95.3307],"Rotation":0},{"Text":"Distr.","TextBB":[512.924,96.7424,527.295,102.441],"Rotation":0},{"Text":"2","TextBB":[529.008,96.7424,532.433,102.441],"Rotation":0},{"Text":"Distr.","TextBB":[512.924,103.852,527.295,109.55],"Rotation":0},{"Text":"3","TextBB":[529.008,103.852,532.433,109.55],"Rotation":0},{"Text":"Mixture","TextBB":[512.924,110.962,533.117,116.66],"Rotation":0},{"Text":"of","TextBB":[534.829,110.962,539.967,116.66],"Rotation":0},{"Text":"Distr.","TextBB":[541.679,110.962,556.051,116.66],"Rotation":0},{"Text":"350","TextBB":[412.206,97.6409,422.481,103.339],"Rotation":0},{"Text":"250","TextBB":[82.3719,124.745,92.6471,130.443],"Rotation":0},{"Text":"0","TextBB":[89.2251,192.558,92.6502,198.256],"Rotation":0},{"Text":"2","TextBB":[582.275,82.6066,585.743,88.3758],"Rotation":0},{"Text":"400","TextBB":[412.206,84.0881,422.481,89.7863],"Rotation":0},{"Text":"0","TextBB":[419.058,192.558,422.483,198.256],"Rotation":0},{"Text":"50","TextBB":[366.803,196.87,373.653,202.568],"Rotation":0},{"Text":"x","TextBB":[586.641,78.8903,589.759,84.6596],"Rotation":0},{"Text":"10","TextBB":[591.493,78.8903,598.429,84.6596],"Rotation":0},{"Text":"1.5","TextBB":[577.078,110.05,585.747,115.819],"Rotation":0},{"Text":"1","TextBB":[582.275,137.518,585.743,143.287],"Rotation":0},{"Text":"0.5","TextBB":[577.078,164.961,585.747,170.73],"Rotation":0},{"Text":"−50","TextBB":[442.133,196.87,452.581,202.568],"Rotation":0},{"Text":"0","TextBB":[490.414,196.87,493.839,202.568],"Rotation":0},{"Text":"(b)","TextBB":[314.811,208.328,329.294,219.536],"Rotation":0},{"Text":"0","TextBB":[582.275,192.43,585.743,198.199],"Rotation":0},{"Text":"50","TextBB":[531.635,196.87,538.485,202.568],"Rotation":0},{"Text":"−50","TextBB":[605.638,196.795,616.215,202.565],"Rotation":0},{"Text":"0","TextBB":[654.521,196.795,657.989,202.565],"Rotation":0},{"Text":"(c)","TextBB":[480.128,208.328,493.938,219.536],"Rotation":0},{"Text":"50","TextBB":[696.257,196.795,703.192,202.565],"Rotation":0},{"Text":"(d)","TextBB":[644.772,208.328,659.255,219.536],"Rotation":0}],"Mention":["segmentation of all database images with respect to all concepts\nof interest is infeasible. A pressing question is then whether it is\npossible to estimate the densities of a semantic class without prior\nsemantic segmentation, i.e. from a training set containing a signif-\nicant percentage of feature vectors from other semantic classes.\nThis question has been studied in the machine learning literature,\nwhere the it is usually referred to asmultiple instance learning [13].\nWhile the problem is still not completely understood, there is strong\nempirical evidence that, if enough images containing the concept of\ninterest are available, the best fit to the density of its training set is\na good approximation to the concept density. The basic idea is that,\nwhile all images will have probability mass on the region of the\nfeature space associated with the concept, the remaining probabil-\nity mass (due to the appearance of other concepts in the images) is\nuniformly spread out throughout the space (because the appearance\nof the remaining concepts is random). Since it has to integrate to\none, this uniform component tends to have small amplitude (in par-\nticular when the feature space is high dimensional). Hence, while\nthe density of the concept may not be dominant in any individual\nimage, the consistent appearance makes it dominant over the en-\ntire training set. This is illustrated in Figure 1 which presents a\nsimulation of this effect, when all classes are Gaussian of mean\n\rZ@\u0001\u0000\nN\n.\u0003\u0002\u0004\u0002 \t\u0017.\u0003\u0002\u0004\u0002\u0006\u0005 and variance \u0007;@\u0001\u0000 \u0002 \u000B\". \tP.\u0003\u0002\u0006\u0005 and the ensemble con-\ntains of .0\t\b\u0002\u0004\u0002\t\u0002 training images with three semantic concepts (the\nconcept of interest, with \r \u0001\u000B\n\u0006\u0002 and \u0007\u0015\u0001\u000B\f , and two others se-\nlected at random).\nAn example on a real image database is provided by Figure 2\nwhich illustrates the quality of the semantic density estimates in-\ndirectly, by presenting their performance in a semantic segmen-\ntation task. In this example, each training image was broken into\n\r\u000F\u000E\u0010\r pixel neighborhoods, and a feature vector extracted from each\nneighborhood. All densities were modeled as Gaussian mixtures,\nand the semantic densities were learned over a set of training im-\nages derived from the Corel data set (see Section 6 for a detailed\ndiscussion of this dataset and the features used). The same fea-\nture extraction procedure was then applied to a set of test images,\nand each feature vector classified into one of the semantic classes\npresent in the image (the semantic classes were obtained from the\ncaption provided with the image). Figure 2 depicts the class indexes\nthat produced the largest posterior probability at each image loca-\ntion, illustrating how each pixel is assigned to each of the classes\n(class indexes are represented in the color bar on the right image).\nThe class at each image location < was determined by\n"],"Page":3,"Number":1,"Type":"Figure","CaptionBB":[73,234,772,275],"Height":1100,"Width":850,"DPI":100,"ImageBB":[80,75,729,221]}