{"Caption":"Figure 7. Lower bounds for speedup using a warm cache for Shore (bottom graph) and percentage of reduction in L1-I cache misses (top graph) of Steps over Shore, for 2-80 concurrent threads. The top line shows the maximum possible reduction. Multiplexing thread execution at the granularity Steps does, results in a larger collective working set which can overwhelm the L1-D cache (when compared to Shore). Figure 6b shows that Steps incurs increasingly more L1-D cache misses as the thread group size increases. For up to four threads, however, the collective working set has com- parable performance to single-thread execution. ","ImageText":[{"Text":"100%","TextBB":[446.083,73.2982,467.886,83.7204],"Rotation":0},{"Text":"Miss","TextBB":[435.553,140.434,447.922,163.25],"Rotation":3},{"Text":"reduction","TextBB":[435.553,91.6716,447.922,137.306],"Rotation":3},{"Text":"80%","TextBB":[449.25,103.382,467.883,113.804],"Rotation":0},{"Text":"1.4","TextBB":[457.333,189.379,467.777,199.804],"Rotation":0},{"Text":"L1-I","TextBB":[580.167,119.17,599.921,131.908],"Rotation":0},{"Text":"miss","TextBB":[602.001,119.17,624.291,131.908],"Rotation":0},{"Text":"reduction","TextBB":[627.92,119.17,674.839,131.908],"Rotation":0},{"Text":"%","TextBB":[677.828,119.17,687.975,131.908],"Rotation":0},{"Text":"upper","TextBB":[691.327,119.17,720.042,131.908],"Rotation":0},{"Text":"limit","TextBB":[723.575,119.17,741.244,131.908],"Rotation":0},{"Text":"L1-I","TextBB":[580.167,134.67,599.922,147.408],"Rotation":0},{"Text":"miss","TextBB":[602.002,134.67,624.293,147.408],"Rotation":0},{"Text":"reduction","TextBB":[627.921,134.67,674.846,147.408],"Rotation":0},{"Text":"%","TextBB":[677.836,134.67,687.983,147.408],"Rotation":0},{"Text":"60%","TextBB":[449.25,134.548,467.883,144.97],"Rotation":0},{"Text":"40%","TextBB":[449.25,164.632,467.883,175.054],"Rotation":0},{"Text":"Speedup","TextBB":[435.553,220.764,447.922,264.667],"Rotation":3},{"Text":"0","TextBB":[473.167,179.132,478.359,189.554],"Rotation":0},{"Text":"10","TextBB":[506.415,179.132,514.689,189.554],"Rotation":0},{"Text":"20","TextBB":[540.663,179.132,551.02,189.554],"Rotation":0},{"Text":"30","TextBB":[575.993,179.132,586.351,189.554],"Rotation":0},{"Text":"40","TextBB":[611.324,179.132,621.682,189.554],"Rotation":0},{"Text":"50","TextBB":[646.655,179.132,657.013,189.554],"Rotation":0},{"Text":"60","TextBB":[681.986,179.132,692.344,189.554],"Rotation":0},{"Text":"70","TextBB":[717.317,179.132,727.675,189.554],"Rotation":0},{"Text":"80","TextBB":[752.648,179.132,763.006,189.554],"Rotation":0},{"Text":"Speedup","TextBB":[668.333,196.834,713.087,209.576],"Rotation":0},{"Text":"Speedup","TextBB":[668.333,212.417,713.085,225.159],"Rotation":0},{"Text":"(float","TextBB":[716.068,212.417,742.151,225.159],"Rotation":0},{"Text":"on)","TextBB":[745.134,212.417,761.432,225.159],"Rotation":0},{"Text":"1.3","TextBB":[457.333,212.213,467.777,222.638],"Rotation":0},{"Text":"1.2","TextBB":[457.333,235.046,467.777,245.471],"Rotation":0},{"Text":"1.1","TextBB":[459.417,257.879,469.861,268.305],"Rotation":0},{"Text":"1","TextBB":[464.667,280.712,469.861,291.138],"Rotation":0},{"Text":"0","TextBB":[474,295.296,479.194,305.721],"Rotation":0},{"Text":"10","TextBB":[507.248,295.296,515.524,305.721],"Rotation":0},{"Text":"20","TextBB":[541.495,295.296,551.938,305.721],"Rotation":0},{"Text":"30","TextBB":[576.825,295.296,587.268,305.721],"Rotation":0},{"Text":"40","TextBB":[612.155,295.296,622.597,305.721],"Rotation":0},{"Text":"50","TextBB":[646.485,295.296,656.844,305.721],"Rotation":0},{"Text":"Concurrent","TextBB":[566.25,305.136,621.154,317.505],"Rotation":0},{"Text":"threads","TextBB":[624.242,305.136,661.281,317.505],"Rotation":0},{"Text":"60","TextBB":[681.816,295.296,692.175,305.721],"Rotation":0},{"Text":"70","TextBB":[717.147,295.296,727.506,305.721],"Rotation":0},{"Text":"80","TextBB":[752.477,295.296,762.836,305.721],"Rotation":0}],"Mention":["Multiplexing thread execution at the granularity Steps\ndoes, results in a larger collective working set which can\noverwhelm the L1-D cache (when compared to Shore).\nFigure 6b shows that Steps incurs increasingly more L1-D\ncache misses as the thread group size increases. For up to\nfour threads, however, the collective working set has com-\nparable performance to single-thread execution.\nFortunately, L1-D cache misses have minimal effect\non execution time (as also seen by the Steps speedup). The\nreason is that L1-D cache misses that hit in the L2 cache\n(i.e., are serviced within 5-10 cycles) can be easily over-\nlapped by out-of-order execution [AD+99]. Moreover, in the\ncontext of Simultaneous Multithreaded Processors (SMT),\nit has been shown that for 8 threads executing simulta-\nneously an OLTP workload and sharing the CPU caches,\nadditional L1-D misses can be eliminated [LB+98].\nOn the other hand, there is no real incentive in\nincreasing the group size beyond 10-20 threads, as the\nupper limit in the reduction of L1-I cache misses is already\n90-95%. Figure 7 plots the Steps speedup (both with float\non\/off) and the percentage of L1-I cache misses reduction\nfor 2-80 concurrent threads. The reason that the speedup\ndeteriorates for groups larger than 10 threads is because of\nthe AMD\u2019s small, 256KB unified L2 cache. In contrast to\nL1-D cache misses, L2-D misses cannot be overlapped by\nout-of-order execution. Steps always splits large groups\n(discussed in Section 4) to avoid the speedup degradation.\n"],"Page":6,"Number":7,"Type":"Figure","CaptionBB":[435,318,762,486],"Height":1100,"Width":850,"DPI":100,"ImageBB":[435,72,765,318]}