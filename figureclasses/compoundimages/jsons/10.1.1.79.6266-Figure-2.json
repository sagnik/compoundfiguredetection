{"Caption":"Figure 2. Systems and results of evaluations: (a) screen shot of the 3 DoF arm simulator, (c) Sarcos robot arm, used as simulated system and for actual robot evaluations in progress. (b) Tracking performance for a planar figure-8 pattern for the 3 DoF arm, and (d) comparison between the analytically obtained optimal control commands in com- parison to the learned ones for one figure-8 cycle of the 3DoF arm. ","ImageText":[{"Text":"(c)","TextBB":[470.721,195.354,479.448,202.278],"Rotation":0},{"Text":"SARCOS","TextBB":[481.528,195.354,513.137,202.278],"Rotation":0},{"Text":"Master","TextBB":[515.215,195.354,538.09,202.278],"Rotation":0},{"Text":"Robot","TextBB":[470.721,202.839,490.696,209.762],"Rotation":0},{"Text":"Arm","TextBB":[492.774,202.839,506.493,209.762],"Rotation":0},{"Text":"0.16","TextBB":[575.867,107.27,590.433,114.394],"Rotation":0},{"Text":"0.14","TextBB":[575.867,117.925,590.433,125.05],"Rotation":0},{"Text":"0.12","TextBB":[575.867,128.688,590.433,135.812],"Rotation":0},{"Text":"0.1","TextBB":[577.799,139.452,588.202,146.576],"Rotation":0},{"Text":"0.08","TextBB":[575.867,150.214,590.433,157.339],"Rotation":0},{"Text":"0.06","TextBB":[575.867,160.906,590.433,168.031],"Rotation":0},{"Text":"0.04","TextBB":[575.867,171.632,590.433,178.757],"Rotation":0},{"Text":"learned","TextBB":[695.151,156.988,721.428,164.495],"Rotation":0},{"Text":"desired","TextBB":[693.871,165.892,719.958,173.399],"Rotation":0},{"Text":"0.44","TextBB":[595.914,184.171,610.48,191.296],"Rotation":0},{"Text":"0.48","TextBB":[617.131,184.171,631.697,191.296],"Rotation":0},{"Text":"0.52","TextBB":[638.382,184.171,652.949,191.296],"Rotation":0},{"Text":"0.56","TextBB":[659.599,184.171,674.165,191.296],"Rotation":0},{"Text":"Hand","TextBB":[596.996,191.257,615.169,198.764],"Rotation":0},{"Text":"coordinate","TextBB":[617.664,191.257,656.108,198.764],"Rotation":0},{"Text":"x","TextBB":[658.606,191.063,662.572,198.817],"Rotation":0},{"Text":"1","TextBB":[662.575,195.229,666.319,200.86],"Rotation":0},{"Text":"(d)","TextBB":[548.812,207.197,557.96,214.121],"Rotation":0},{"Text":"Optimal","TextBB":[560.039,207.197,585.825,214.121],"Rotation":0},{"Text":"vs","TextBB":[587.905,207.197,595.39,214.121],"Rotation":0},{"Text":"Learned","TextBB":[597.469,207.197,624.938,214.121],"Rotation":0},{"Text":"Motor","TextBB":[627.018,207.197,646.15,214.121],"Rotation":0},{"Text":"Command","TextBB":[648.23,207.197,682.755,214.121],"Rotation":0},{"Text":"60","TextBB":[565.603,219.653,573.927,226.778],"Rotation":0},{"Text":"a","TextBB":[581.801,223.138,585.94,230.892],"Rotation":0},{"Text":"11","TextBB":[585.943,222.313,593.429,232.933],"Rotation":0},{"Text":"50","TextBB":[565.603,230.727,573.927,237.851],"Rotation":0},{"Text":"40","TextBB":[565.603,241.834,573.927,248.958],"Rotation":0},{"Text":"30","TextBB":[565.603,252.907,573.927,260.032],"Rotation":0},{"Text":"a","TextBB":[577.043,255.242,581.182,262.996],"Rotation":0},{"Text":"2","TextBB":[584.926,254.419,588.67,260.049],"Rotation":0},{"Text":"1","TextBB":[581.185,259.408,584.929,265.039],"Rotation":0},{"Text":"20","TextBB":[565.603,263.981,573.927,271.106],"Rotation":0},{"Text":"10","TextBB":[565.603,275.053,573.927,282.178],"Rotation":0},{"Text":"0","TextBB":[567.926,286.127,572.088,293.251],"Rotation":0},{"Text":"a","TextBB":[583.51,286.653,587.649,294.407],"Rotation":0},{"Text":"13","TextBB":[587.651,285.83,595.137,296.45],"Rotation":0},{"Text":"-10","TextBB":[563.194,297.268,574.011,304.393],"Rotation":0},{"Text":"0","TextBB":[575.375,300.139,579.536,307.264],"Rotation":0},{"Text":"0.5","TextBB":[597.169,300.139,607.573,307.264],"Rotation":0},{"Text":"Taskspace","TextBB":[547.115,255.053,554.623,292.674],"Rotation":3},{"Text":"motor","TextBB":[547.115,230.587,554.623,252.558],"Rotation":3},{"Text":"commands","TextBB":[557.07,246.362,564.577,285.185],"Rotation":3},{"Text":"=","TextBB":[554.372,239.335,566.145,243.863],"Rotation":3},{"Text":"1","TextBB":[561.041,235.903,566.672,239.647],"Rotation":3},{"Text":"(b)","TextBB":[575.226,93.0399,584.374,99.9632],"Rotation":0},{"Text":"Tracking","TextBB":[586.453,93.0399,615.152,99.9632],"Rotation":0},{"Text":"Performance","TextBB":[617.233,93.0399,660.08,99.9632],"Rotation":0},{"Text":"(a)","TextBB":[472.524,93.0399,481.671,99.9632],"Rotation":0},{"Text":"3","TextBB":[483.751,93.0399,487.912,99.9632],"Rotation":0},{"Text":"DoF","TextBB":[489.993,93.0399,504.134,99.9632],"Rotation":0},{"Text":"Robot","TextBB":[506.212,93.0399,526.187,99.9632],"Rotation":0},{"Text":"Arm","TextBB":[528.264,93.0399,541.984,99.9632],"Rotation":0},{"Text":"Hand","TextBB":[566.071,159.593,573.578,177.765],"Rotation":3},{"Text":"coordinate","TextBB":[566.071,118.653,573.578,157.097],"Rotation":3},{"Text":"x","TextBB":[565.876,112.189,573.631,116.156],"Rotation":3},{"Text":"2","TextBB":[570.043,108.443,575.674,112.188],"Rotation":3},{"Text":"1","TextBB":[622.451,300.139,626.613,307.264],"Rotation":0},{"Text":"Time","TextBB":[649.193,290.109,666.745,297.616],"Rotation":0},{"Text":"t","TextBB":[669.239,289.914,672.555,297.668],"Rotation":0},{"Text":"1.5","TextBB":[644.289,300.139,654.693,307.264],"Rotation":0},{"Text":"2","TextBB":[669.569,300.139,673.731,307.264],"Rotation":0},{"Text":"learned","TextBB":[694.406,273.854,720.683,281.361],"Rotation":0},{"Text":"optimal","TextBB":[693.125,282.757,719.833,290.264],"Rotation":0}],"Mention":["We evaluated our approach on two different simu-\nlated, physically realistic robots: (i) a three degree-of-\nfreedom (DoF) planar robot arm and (ii) a seven DoF\nsimulated SARCOS master robot arm (Figure 2 (a)).\nAn implementation on the real, physical SARCOS\nmaster robot arm (Figure2(c)) is currently in progress.\nExperiments were conducted as follows: first, learning\nthe forward models and an initial control policy in each\nlocal model was obtained from random point-to-point\nmovements in joint space using a simple PD control\n","law. This \u201Cmotor babbling\u201D exploration was necessary\nin order bootstrap learning with some initial data to\nprevent the rather slow learning as observed in similar\ndirect-inverse learning approaches (Jordan & Rumel-\nhart, 1992). The measured end-effector accelerations\nserved as desired acceleration in Eq. (21), and all other\nvariables for learning the local controllers were measur-\nable as well. Subsequently, the learning controller was\nused on-policy with the normally distributed actuator\nnoise serving as exploration. Both robots learned to\ntrack desired trajectories with high accuracy, as shown\nin Figure 2 (b). For the three DoF arm, we verified the\nquality of the learned control commands in compari-\nson to the analytical solution, given in Eq. (4): Fig-\nure 2(d) demonstrates that the motor commands of\nthe learned and analytically optimal case are almost\nidentical. Learning results of the simulated seven DoF\nSARCOS robot achieved almost the same endeffector\ntracking quality as shown in Figure 2(b) (and is there-\nfore not shown separately here). However, the joint\ncommands were not quite as close to the optimal ones\nas for the 3 DoF arm - the rather high dimensional\nlearning space of the 7 DoF arm most likely requires\nmore extensive training and more careful tuning of the\nLWPR learning algorithm to achieve local lineariza-\ntions with very high accuracy and with enough data\nto find the optimal solution. The 3 DoF required about\n2 hours of real-time training training, while the 7 DoF\narm was run for about 6 hours of real-time training.\n"],"Page":5,"Number":2,"Type":"Figure","CaptionBB":[426,331,754,452],"Height":1100,"Width":850,"DPI":100,"ImageBB":[453,90,727,309]}