{"Caption":"Figure 2: Trajectory of the IGA mixed strategy against the Hyper-Q strategy starting from a single exploring start. Dots show Hyper-Q player\u2019s cumulative (rescaled) reward. ","ImageText":[{"Text":"Asymptotic","TextBB":[379.954,371.249,427.767,380.293],"Rotation":0},{"Text":"IGA","TextBB":[430.485,371.249,447.332,380.293],"Rotation":0},{"Text":"Trajectory","TextBB":[450.051,371.249,493.513,380.293],"Rotation":0},{"Text":"0.7","TextBB":[285.631,385.916,299.222,394.96],"Rotation":0},{"Text":"\u2019IGA_Rock_Prob\u2019","TextBB":[329.836,393.605,404.822,402.649],"Rotation":0},{"Text":"\u2019IGA_Paper_Prob\u2019","TextBB":[326.023,403.382,404.822,412.427],"Rotation":0},{"Text":"\u2019HyperQ_Reward\u2019","TextBB":[327.676,413.16,404.822,422.204],"Rotation":0},{"Text":"0.65","TextBB":[280.195,402.449,299.222,411.493],"Rotation":0},{"Text":"0.6","TextBB":[285.631,418.982,299.222,428.027],"Rotation":0},{"Text":"0.55","TextBB":[280.195,435.516,299.222,444.56],"Rotation":0},{"Text":"0.5","TextBB":[285.631,452.049,299.222,461.093],"Rotation":0},{"Text":"0.45","TextBB":[280.195,468.582,299.222,477.627],"Rotation":0},{"Text":"0.4","TextBB":[285.631,485.116,299.222,494.16],"Rotation":0},{"Text":"0.35","TextBB":[280.195,501.649,299.222,510.693],"Rotation":0},{"Text":"0.3","TextBB":[285.631,518.182,299.222,527.227],"Rotation":0},{"Text":"0.25","TextBB":[280.195,534.716,299.222,543.76],"Rotation":0},{"Text":"0.2","TextBB":[285.631,551.249,299.222,560.293],"Rotation":0},{"Text":"0","TextBB":[302.326,561.027,307.763,570.071],"Rotation":0},{"Text":"10000","TextBB":[357.276,561.027,384.458,570.071],"Rotation":0},{"Text":"20000","TextBB":[423.098,561.027,450.28,570.071],"Rotation":0},{"Text":"30000","TextBB":[488.964,561.027,516.147,570.071],"Rotation":0},{"Text":"40000","TextBB":[554.787,561.027,581.969,570.071],"Rotation":0},{"Text":"Time","TextBB":[412.01,575.693,433.736,584.738],"Rotation":0},{"Text":"Steps","TextBB":[436.455,575.693,461.456,584.738],"Rotation":0}],"Mention":["Part of Hyper-Q\u2019s advantage comes from exploiting transient behavior starting from a ran-\ndom initial condition. In addition, Hyper-Q also exploits the asymptotic behavior of IGA,\nas shown in figure 2. This plot shows that the initial transient lasts at most a few thousand\ntime steps. Afterwards, the Hyper-Q policy causes IGA to cycle erraticly between two dif-\nferent probabilites for Rock and two different probabilities for Paper, thus preventing IGA\nfrom reaching the Nash mixed strategy. The overall profit to Hyper-Q during this cycling\nis positive on average, as shown by rising cumulative Hyper-Q reward. The observed cy-\ncling with positive profitability is reminiscent of an algorithm called PHC-Exploiter [3] in\nplay against a PHC player. An interesting difference is that PHC-Exploiter uses an explicit\nmodel of its opponent\u2019s behavior, whereas no such model is needed by a Hyper-Q learner.\n"],"Page":6,"Number":2,"Type":"Figure","CaptionBB":[173,602,675,632],"Height":1100,"Width":850,"DPI":100,"ImageBB":[278,368,584,587]}