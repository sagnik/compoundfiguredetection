{"Caption":"Figure 1. Example images from the PandaCam dataset. Note the high variability of view points, illumination, and object pose. ","ImageText":[],"Mention":["In this work, we investigate object detection in the con-\ntext of a real application which is not covered by these two\nscenarios. This application involves objects that lack many\nof the features commonly used for object detection, and\nwhich we denote amorphous. Strictly speaking, amorphous\nobjects have no distinctive edge configurations, texture, or\na well defined shape. They can be found in science fiction\nmovies, in the form of jelly-like creatures that can take any\ndesirable shape. While, in the real world, truly amorphous\nobjects are rare, many real objects are close to amorphous\n(e.g. a jellyfish, a bean bag, etc.), and an even larger set\nquasi-amorphous. By this, we refer to objects that can have\nvery characteristic appearance under some canonical poses,\nbut appear amorphous under others. Many such examples\nexist in the animal world. This is illustrated by Figure 1,\nwhich shows a Panda bear under multiple poses. While the\nPanda face is very iconic, faceless poses tend to be quite\namorphous. We will not worry further about these fine dis-\ntinctions, simply referring to such objects as amorphous.\n","level learns discriminant templates of saliency response,\nwhich are then used to detect blobs of saliency compatible\nwith the target object. This is again implementedwith a top-\ndown discriminant saliency model, tuned for object detec-\ntion, which operates on saliency templates rather than image\nfeatures. Altogether, this classifier is selective, yet robust\nenough to detect highly deformable objects of reduced vi-\nsual structure. The use of saliency, rather than appearance,\ntemplates also makes it robust to pose variation.\nThe second contribution of this work is a dataset for the\nevaluation of amorphous object detectors. This dataset was\nassembled from video of a real animal habitat, the Panda\nbear exhibit of the San Diego Zoo, over the period of one\nyear [1]. It resembles current pedestrian datasets, in that it\nrequires the detection of a few objects under various imag-\ning contexts. On the other hand, it is similar to object cat-\negory datasets, in the sense that Pandas have wide variabil-\nity of appearance. As can be seen from Figure 1, this is\nin part because they are highly deformable objects, and in\npart because the video feed is collected from multiple cam-\neras, with multiple fields of view (varying backgrounds), at\ndifferent distances from the Panda exhibit (varying scales),\nfrom different angles (varying poses), at different locations\n(indoors vs outdoors), at multiple times of the day, week,\nand year (different atmospheric conditions, variable shad-\ning, lighting, etc.), and with different potential occluders.\nOne of the attractives of the PandaCam dataset, is that it\nchallenges currently prevalent beliefs about object recogni-\ntion. For example, results on current datasets suggest that\nnormalized representations of local image orientation are\ncritically important for object detection. In fact, these rep-\nresentations are the only unifying link between the success\nof bag-of-features (almost invariably based on SIFT) on\nthe PASCAL end of the spectrum, and template-based ap-\nproaches (usually based on HOG) on the pedestrian end of\nthe spectrum. On PandaCam, a comparison of the proposed\ndetector with an equivalent approach built on templates of\nSIFT response shows that saliency templates achieve sub-\nstantially higher localization performance. As an object de-\ntector, the proposed approach is also shown to achieve bet-\nter performance than state-of-the art methods for template-\nbased detection, namely the discriminant parts-based model\nof [9], detection based on the bag-of-features model [18],\nthe sparse coded spatial pyramid matching method of [30],\nand the Viola Jones detector [28].\n","tic curve of the entropy-based detector is shown Figure 2 b),\nfor Î± = 1. In this case, all degrees of freedom are exhausted\nonce the background distribution is fixed, and the saliency\ndetector is always a detector of feature presence.\n","Amorphous objects lack many of the features that are\ncommonly used as cues for object detection. They do not\nhave many distinctive edges, may not have a very distin-\nguishable texture, and are characterized by a large shape\nvariability. In fact, as shown in Figure 1, they can be thought\nof as blobs of low image complexity. However simple blob\ndetection [4, 29] is unlikely to successfully find Pandas, as\nthere are many blob-like regions in the backgrounds of Fig-\nure 1: smooth rocks, tree trunks, light reflections on interior\nwalls, areas of the exhibit floor, etc. One possibility is to\nrely on discriminant blob detection, by identifying blob-like\nregions in the responses of features that are discriminant for\nPanda detection. These are regions of feature absence, i.e.\nwhere features that are usually active for natural images,\nhave a much weaker response to the Panda stimulus. Fea-\nture absence is naturally detected by discriminant saliency.\n"],"Page":1,"Number":1,"Type":"Figure","CaptionBB":[427,668,757,694],"Height":1100,"Width":850,"DPI":100,"ImageBB":[441,314,745,654]}