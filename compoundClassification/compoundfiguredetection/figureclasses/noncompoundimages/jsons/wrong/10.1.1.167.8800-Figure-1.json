{"Caption":"Figure 1. (a) Detection hypotheses are generated for each frame independently. (b) Particle filtering is used to link hypotheses across frames. (c) Action tracks. (d) Hough voting by 3D patches for action label and center. ","ImageText":[{"Text":"(a)","TextBB":[129.718,262.056,143.863,275.424],"Rotation":0},{"Text":"(b)","TextBB":[313.933,262.056,328.791,275.424],"Rotation":0},{"Text":"(c)","TextBB":[515.827,262.056,529.972,275.424],"Rotation":0},{"Text":"(d)","TextBB":[645.489,262.056,660.347,275.424],"Rotation":0}],"Mention":["We approach the high dimensionality problem by sep-\narating the voting into two stages and hence two lower-\ndimensional spaces. In an initial spatial localization stage,\nwe apply a Hough forest trained for people detection [11]\nand generate detection hypotheses for each frame of the\nvideo sequence independently (Fig. 1(a)). Due to the strong\ncorrelation of the detections\u2019 location and scale across a se-\nquence, the votes can be assembled across time by a particle\nfilter into tracks (Fig. 1(b)). For instance, a parallelepiped\nstructure would result for a translation. The detection tracks\nare then mapped to a cuboid representation, which we call\n\u201Caction tracks\u201D, to obtain a location and scale invariant rep-\nresentation of the person in time (Fig. 1(c)). In a subsequent\nclassification and temporal localization stage, votes are then\ncast for the action\u2019s label and spatio-temporal center on the\nnormalized action track (Fig. 1(d), 2).\n","shown in Fig. 1(c), i.e. the sequence is a 3D cuboid. This\nconcept is then generalized in Section 3.3.\n","is a 3D patch (e.g. of 16x16x5 pixels) sampled from\nthe action track as illustrated by the colored cuboids in\nFig. 1(d)\n","In order to obtain action tracks from the test sequences,\ni.e. a cuboid representation normalized by scale and posi-\ntion of the human, we learn the mapping from the image\ndomain to a 3D Hough space that encodes position and\nscale of a human. We train a Hough forest for the spatial\ndomain similar to Section 3, where we use cropped and\nscale-normalized images of humans as positive examples\nand background images as negative examples. As features,\nwe use color and histograms of gradients [7]. The voting is\nperformed for each frame independently and detections are\nused to initialize an action track as illustrated in Fig. 1.\n","mined. The term V1 measures the response in the Hough\nspace V (Fig. 1(a)) for the candidate st:\n","As image features, we use the HSV colour space and a lo-\ncal binary pattern operator [24]. The extracted bounding\nboxes for a track are then normalized into spatial- and scale-\ninvariant cuboids as shown in Fig. 1.\n"],"Page":2,"Number":1,"Type":"Figure","CaptionBB":[68,279,758,308],"Height":1100,"Width":850,"DPI":100,"ImageBB":[83,99,744,275]}