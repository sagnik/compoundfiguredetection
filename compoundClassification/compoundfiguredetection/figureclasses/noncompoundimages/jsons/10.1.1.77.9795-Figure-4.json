{"Caption":"Figure 4. Median performance over 100 runs for the dis- counted reward in the grid domain. Error bars correspond to the first and third quartiles. ","ImageText":[{"Text":"55","TextBB":[106.269,290.312,115.293,297.819],"Rotation":0},{"Text":"50","TextBB":[106.269,308.177,115.293,315.684],"Rotation":0},{"Text":"Optimal","TextBB":[154.37,308.121,182.329,315.628],"Rotation":0},{"Text":"Discounted","TextBB":[94.2293,385.504,102.987,432.864],"Rotation":3},{"Text":"Reward","TextBB":[94.2293,350.254,102.987,382.872],"Rotation":3},{"Text":"45","TextBB":[106.269,326.044,115.293,333.551],"Rotation":0},{"Text":"T","TextBB":[220.31,343.145,223.615,348.15],"Rotation":0},{"Text":"(Ψ","TextBB":[194.131,345.556,201.734,351.812],"Rotation":0},{"Text":"P","TextBB":[203.591,345.556,208.102,351.812],"Rotation":0},{"Text":"+","TextBB":[209.982,345.556,213.932,351.812],"Rotation":0},{"Text":"P","TextBB":[215.812,345.556,220.323,351.812],"Rotation":0},{"Text":"Ψ)\/2","TextBB":[225.466,343.581,238.713,352.393],"Rotation":0},{"Text":"40","TextBB":[106.269,343.937,115.293,351.444],"Rotation":0},{"Text":"35","TextBB":[106.269,361.802,115.293,369.309],"Rotation":0},{"Text":"30","TextBB":[106.269,379.697,115.293,387.204],"Rotation":0},{"Text":"25","TextBB":[106.269,397.562,115.293,405.069],"Rotation":0},{"Text":"20","TextBB":[106.269,415.456,115.293,422.963],"Rotation":0},{"Text":"15","TextBB":[106.269,433.322,115.293,440.829],"Rotation":0},{"Text":"(W+W","TextBB":[260.69,442.436,279.66,448.692],"Rotation":0},{"Text":"T","TextBB":[279.655,440.026,282.961,445.03],"Rotation":0},{"Text":")\/2","TextBB":[282.952,442.436,290.844,448.692],"Rotation":0},{"Text":"10","TextBB":[106.269,451.216,115.293,458.723],"Rotation":0},{"Text":"5","TextBB":[110.777,469.081,115.29,476.588],"Rotation":0},{"Text":"0","TextBB":[110.777,486.974,115.29,494.481],"Rotation":0},{"Text":"0","TextBB":[114.018,492.47,118.53,499.977],"Rotation":0},{"Text":"10","TextBB":[160.542,492.47,169.566,499.977],"Rotation":0},{"Text":"20","TextBB":[209.319,492.47,218.344,499.977],"Rotation":0},{"Text":"30","TextBB":[258.126,492.47,267.151,499.977],"Rotation":0},{"Text":"40","TextBB":[306.904,492.47,315.929,499.977],"Rotation":0},{"Text":"50","TextBB":[355.711,492.47,364.736,499.977],"Rotation":0},{"Text":"Number","TextBB":[191.567,503.052,225.236,511.81],"Rotation":0},{"Text":"of","TextBB":[227.868,503.052,235.764,511.81],"Rotation":0},{"Text":"Basis","TextBB":[238.396,503.052,261.546,511.81],"Rotation":0},{"Text":"Functions","TextBB":[264.178,503.052,305.223,511.81],"Rotation":0}],"Mention":["Learned policies were evaluated to determine the dis-\ncounted reward given a uniform initial state distribu-\ntion. Thus, a policy was tested by starting an agent\nonce in each of the 200 states and letting it run un-\ntil reaching the goal or exceeding 100 steps. The re-\nward was averaged over the 200 di\u000Berent starting po-\nsitions. These experiments were repeated 100 times.\nThe median over the 100 runs is shown in Figure 4\nwith error bars corresponding to the \frst and third\nquartiles. Performance for both symmetrizations was\npoor when using less than 20 basis functions. The\n","with this setup and achieved similar results to those\nshown in Figure 4 although the gap between the curves\nwas not quite as large. Thus, policies learned using the\n"],"Page":6,"Number":4,"Type":"Figure","CaptionBB":[75,536,402,581],"Height":1100,"Width":850,"DPI":100,"ImageBB":[92,288,388,512]}