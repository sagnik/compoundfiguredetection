{"Caption":"Figure 8. Typical results from HEH and our algorithm. Row 1: Original Image. Row 2: 3-d model generated by HEH, Row 3 and 4: 3-d model generated by our algorithm. (Note that the screenshots cannot be simply obtained from the original image by an affine transformation.) In image 1, HEH makes mistakes in some parts of the foreground rock, while our algorithm predicts the correct model; with the rock occluding the house, giving a novel view. In image 2, HEH algorithm detects a wrong ground-vertical boundary; while our algorithm not only finds the correct ground, but also captures a lot of non-vertical structure, such as the blue slide. In image 3, HEH is confused by the reflection; while our algorithm produces a correct 3-d model. In image 4, HEH and our algorithm produce roughly equivalent results\u2014HEH is a bit more visually pleasing and our model is a bit more detailed. In image 5, both HEH and our algorithm fail; HEH just predict one vertical plane at a incorrect location. Our algorithm predicts correct depths of the pole and the horse, but is unable to detect their boundary; hence making it qualitatively incorrect. ","ImageText":[],"Mention":["may still show small errors.\nOur algorithm gives qualitatively correct models for\n64.9% of images as compared to 33.1% by HEH. The qual-\nitative evaluation was performed by a person not associ-\nated with the project following the guidelines in Footnote 3.\nHEH generate a \u201Cphoto-popup\u201D effect by folding the im-\nages at \u201Cground-vertical\u201D boundaries\u2014an assumption which\nis not true for a significant number of images; therefore, their\nmethod fails in those images. Some typical examples of the\n3-d models are shown in Fig. 8. (Note that all the test cases\nshown in Fig. 1, 8 and 9 are from the dataset downloaded\nfrom the internet, except Fig. 9a which is from the laser-test\ndataset.) These examples also show that our models are of-\nten more detailed than HEH, in that they are often able to\nmodel the scene with a multitude (over a hundred) of planes.\nWe performed a further comparison to HEH. Even when\nboth HEH and our algorithm is evaluated as qualitatively\ncorrect on an image, one result could still be superior. There-\nfore, we asked the person to compare the two methods, and\ndecide which one is better, or is a tie.4 Table 2 shows that our\nalgorithm performs better than HEH in 62.1% of the cases.\nFull documentation describing the details of the unbiased\nhuman judgment process, along with the 3-d flythroughs\nproduced by our algorithm and HEH, is available online at:\n","the image (occupying more than 15% area in the image) is in wrong location\nwith respect to its neighbors, or if the orientation of the plane is more than\n30 degrees wrong. For example, if HEH fold the image at incorrect place\n(see Fig. 8, image 2), then it is counted as an error. Similarly, if we predict\ntop of a building as far and the bottom part of building near, making the\nbuilding tilted\u2014it would count as an error.\n"],"Page":7,"Number":8,"Type":"Figure","CaptionBB":[68,514,758,648],"Height":1100,"Width":850,"DPI":100,"ImageBB":[64,79,752,510]}